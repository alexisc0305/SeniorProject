{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial: https://github.com/ashima0109/VGG-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "def build(width, height, depth):\n",
    "    # initialize model, input shape, and channel dimension\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1  \n",
    "\n",
    "    # CONV -> RELU -> POOL layer set\n",
    "    model.add(Conv2D(32, (3, 3), padding = \"same\", input_shape = inputShape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # (CONV -> RELU) * 2 -> POOL layer set\n",
    "    model.add(Conv2D(64, (3, 3), padding = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Conv2D(64, (3, 3), padding = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # (CONV -> RELU) * 3 -> POOL layer set\n",
    "    model.add(Conv2D(128, (3, 3), padding = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Conv2D(128, (3, 3), padding = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Conv2D(128, (3, 3), padding = \"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # FC -> RELU layer set\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    # softmax classifier\n",
    "    model.add(Dense(11, kernel_regularizer = 'l2'))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    # return constructed model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "def preprocessing():\n",
    "    DIRECTORY = r'new_dataset'\n",
    "    CATEGORIES = ['1', '2A', '2B', '2C', '3A', '3B', '3C', '4A', '4B', '4C', 'no_hair']\n",
    "    ENCODINGS = {\n",
    "        '1': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '2A': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '2B': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '2C': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '3A': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        '3B': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        '3C': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        '4A': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        '4B': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        '4C': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        'no_hair': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        folder = os.path.join(DIRECTORY, category)\n",
    "\n",
    "        for img in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, img)\n",
    "            if (\".DS_Store\" in img_path):\n",
    "                continue\n",
    "            img_arr = cv2.imread(img_path)\n",
    "            img_arr = cv2.resize(img_arr, (224, 224))\n",
    "            encoding = ENCODINGS.get(category)\n",
    "            data.append([img_arr, encoding])\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for features, labels in data:\n",
    "        X.append(features)\n",
    "        Y.append(labels)\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "def test(x_test, y_test, model):\n",
    "    for i in range(len(x_test)):\n",
    "        img = x_test[i]\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        prediction = model.predict(img.reshape(-1, 224, 224, 3))\n",
    "        print(\"Prediction = \" + str(prediction))\n",
    "        print(\"Correct label = \" + str(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validating\n",
    "def train_and_validate():\n",
    "    tup = preprocessing()\n",
    "    X = tup[0]\n",
    "    Y = tup[1]\n",
    "    \n",
    "    x_remainder, x_test, y_remainder, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_remainder, y_remainder, test_size = 0.1, random_state = 42)\n",
    "\n",
    "    x_train = x_train / 255.0\n",
    "    x_valid = x_valid / 255.0\n",
    "    x_test = x_test / 255.0     \n",
    "    \n",
    "    model = build(224, 224, 3)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(x_train, y_train, epochs = 20, batch_size = 20, validation_data = (x_valid, y_valid))\n",
    "\n",
    "    test(x_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hair prediction -- this part needs to be updated\n",
    "def make_prediction(img_path, model):\n",
    "    img_arr = cv2.imread(img_path)\n",
    "    img_arr = cv2.resize(img_arr, (224, 224))\n",
    "    prediction = model.predict(img_arr.reshape(-1, 224, 224, 3))\n",
    "\n",
    "    # this might not be correct\n",
    "    ENCODINGS = {\n",
    "        '1': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '2A': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '2B': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '2C': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '3A': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        '3B': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        '3C': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        '4A': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        '4B': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        '4C': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        'no_hair': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "    }\n",
    "\n",
    "    for encoding in ENCODINGS:\n",
    "        if prediction == encoding:\n",
    "            return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
